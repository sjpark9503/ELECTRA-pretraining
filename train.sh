CUDA_VISIBLE_DEVICES=1,2,3,4 python3 run_discriminative_task.py --model_type=electra --config_name=google/electra-small-discriminator --tokenizer_name=bert-base-uncased --train_data_file=/home/edlab/sjpark/data/bert_train.txt --mode=mlm --output_dir=pretrained_electra --do_train --logging_dir=./logger/20200810_ELECTRA --seed=1234 --per_device_train_batch_size=64 --fp16 --num_train_epochs=40 --learning_rate=5e-4 --warmup_steps=10000 --logging_steps=100 --save_steps=10000 --max_steps=1000000 --block_size=128 
